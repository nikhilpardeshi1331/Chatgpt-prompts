from google.cloud import storage
import csv
import io

def get_latest_csv_file_from_gcs(bucket_name, folder_path):
    """
    Lists files in the GCS folder and returns the latest CSV file.
    
    :param bucket_name: Name of the GCS bucket.
    :param folder_path: Path to the folder in the GCS bucket.
    :return: The path to the latest CSV file in the folder.
    """
    # Initialize a GCS client
    client = storage.Client()
    
    # Get the bucket
    bucket = client.bucket(bucket_name)
    
    # List all the blobs in the folder
    blobs = bucket.list_blobs(prefix=folder_path)
    
    # Filter CSV files from the folder
    csv_files = [blob.name for blob in blobs if blob.name.endswith('.csv')]
    
    if not csv_files:
        raise FileNotFoundError(f"No CSV files found in the folder {folder_path}")

    # For now, we just return the first CSV file
    latest_csv = csv_files[0]
    
    return latest_csv

def read_gcs_csv_to_dict(bucket_name, blob_name):
    """
    Reads a CSV file from GCS and converts each row into a dictionary.
    
    :param bucket_name: Name of the GCS bucket.
    :param blob_name: Path to the CSV file in the GCS bucket.
    :return: List of dictionaries with column names as keys.
    """
    # Initialize a GCS client
    client = storage.Client()
    
    # Get the bucket and the blob (file)
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)

    # Download the blob's content as a string
    csv_data = blob.download_as_text()

    # Read the CSV from the string data
    data = []
    csv_reader = csv.DictReader(io.StringIO(csv_data))

    # Iterate over each row and store it as a dictionary
    for row in csv_reader:
        data.append(row)

    return data

def run(argv=None):
    # GCS bucket and folder path
    bucket_name = 'your-gcs-bucket'
    folder_path = 'ns_pega_etl/output/'
    
    # Get the latest CSV file in the folder dynamically
    csv_blob_path = get_latest_csv_file_from_gcs(bucket_name, folder_path)
    
    print(f"Latest CSV file: {csv_blob_path}")
    
    # Read the CSV file from GCS and convert it to a list of dictionaries
    result_dicts = read_gcs_csv_to_dict(bucket_name, csv_blob_path)
    
    # Print the result to verify
    for result in result_dicts:
        print(result)

if __name__ == '__main__':
    run()
